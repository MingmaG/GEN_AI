# ðŸš€  Generative AI & LangChain Learning 

Welcome to my **Gen AI Learning Repository**!  
This repo documents my personal journey in exploring **Generative AI**, **LangChain**, and **LLM application development** â€” from the basics to building real-world projects.

---

## ðŸŒ± About This Repository

This repository serves as my **learning log** and **code practice space** as I explore:
- ðŸ§  **LangChain** â€“ framework for developing LLM-powered applications  
- ðŸ¤– **Prompt Engineering** â€“ designing and structuring effective prompts  
- ðŸ”— **Runnables & Chains** â€“ understanding data flow and model composition  
- ðŸ“„ **Document Loaders & Text Splitters** â€“ for building context-aware systems  
- ðŸ’¬ **Chat Models** â€“ connecting LLMs with conversational interfaces  
- ðŸ§© **Parsers & Output Structuring** â€“ making model outputs usable and reliable  

---

## ðŸ“š Folder Structure

genai-learning/
â”œâ”€â”€ chatmodels/
â”œâ”€â”€ runnables/
â”œâ”€â”€ document_loaders/
â”œâ”€â”€ chains/
â”œâ”€â”€ prompts/
â””â”€â”€ README.md

---

## ðŸ§© Key Concepts Iâ€™m Learning

| Concept | Description |
|----------|--------------|
| **PromptTemplate** | How to define reusable prompt structures |
| **Runnable** | Standardized execution interface for any component |
| **DocumentLoader** | Load and preprocess text for retrieval or summarization |
| **Parser** | Convert raw LLM output into structured data |
| **Chains** | Combine multiple components to create workflows |
| **Agents (future)** | Automating decisions with LLM reasoning |

---

## ðŸ§  Example Code Snippet

```python
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.schema.output_parser import StrOutputParser

prompt = PromptTemplate(
    template="Write a short poem about {topic}.",
    input_variables=["topic"]
)

model = ChatOpenAI()
parser = StrOutputParser()

result = parser.invoke(
    model.invoke(
        prompt.invoke({"topic": "sunrise"})
    )
)

print(result)
